{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75980f7d-3327-4340-8d66-73fcc2744e61",
   "metadata": {},
   "source": [
    "# Lab 6 - Convolutional Neural Networks\n",
    "by Rebecca Kuhlman, Sam Yao, and Michael Amberg\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cf28bb",
   "metadata": {},
   "source": [
    "Business Understanding\n",
    "Identifying the type of brain tumor a patient has is an important step in figuring out the treatment plan of a patient. They can be diagnosed via MRI imaging, leading to interest in using machine learning to diagnose the patient. Having a second opinion on brain tumor diagnoses would help improve patient care and outcomes, and lessen stress on doctors. A machine learning model could also speed up analysis time and pick out which patients are in need of urgent treatment.\n",
    "In this dataset, there is glioma, meningioma, and pituitary tumors, as well as MRI images with no tumors. Glioma tumors are usually malignant, while meningioma and pituitary tumors are usually benign. Different types of tumors are made of different types of cells and have a location where they are most likely to be located. More information can be found at: https://www.mayoclinic.org/diseases-conditions/brain-tumor/symptoms-causes/syc-20350084\n",
    "There are many other types of tumors that future algorithms will be need to address. The majority of other types of tumors are more common in children, while the set we are dealing with are all adult brain images.\n",
    "Because the model deals with health conditions that have extreme affects on the patient, model accuracy is extremely important. Furthermore, accuracy must fine-tuned to avoid fatal misdiagnosis. While incorrectly marking a patient with a benign tumor as malignant is wasteful, the adverse affects are minimal. Inversely, misdiagnosing a malignant tumor as benign may have fatal effects for the patient. Therefore, the designed model must minimize the rate of false negatives with accuracy of 95% or more.\n",
    "It should be noted that the majority of misdiagnose of brain tumors happen before a brain scan or related test is ordered. https://paulandperkins.com/brain-tumors/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd39dd5f-dd06-43f1-bef8-d848a1ade022",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2a1eb6-f1e6-4a3f-8695-ea35db15d52f",
   "metadata": {},
   "source": [
    "[1.5 points] \n",
    "Choose and explain what metric(s) you will use to evaluate your algorithmâ€™s performance. You should give a detailed argument for why this (these) metric(s) are appropriate on your data. That is, why is the metric appropriate for the task (e.g., in terms of the business case for the task). Please note: rarely is accuracy the best evaluation metric to use. Think deeply about an appropriate measure of performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7357d9e8-c526-44d4-a1cc-7237de733f0c",
   "metadata": {},
   "source": [
    "Because we will be dealing with identifying brain tumors, we want to use Recall. The equation for Recall takes into account False Negatives, which would be very bad if you falsely cleared someone of brain tumors, but they did in fact have a tumor. This will be a high stakes identification, so at the very least our recall score should be 85% accuarate to be deployed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324c547d-94a5-43fc-ba4c-bc85beff2860",
   "metadata": {},
   "source": [
    "[1.5 points] Choose the method you will use for dividing your data into training and testing (i.e., are you using Stratified 10-fold cross validation? Shuffle splits? Why?). Explain why your chosen method is appropriate or use more than one method as appropriate. Convince me that your cross validation method is a realistic mirroring of how an algorithm would be used in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53079ff1-9b88-4009-9e8a-47e6a59aa65a",
   "metadata": {},
   "source": [
    "We could try Stratified 10 k-fold validation, because it seemed to be effective from the results we had in the last lab. I have no idea if this would extend to image data, but we could give it a try.\n",
    "Stratified 10 k-fold validation is most effective with small amounts of imbalanced data. We have to think about balance a lot in our data as our tumor categories will have differing likelihoods, and we have a lot of different types of MRI photos.\n",
    "In a deployment setting, different tumors (or when we are actually getting a tumor) will come up at different rates. There are many types of tumors with different subcategories, we will only be training our program for 3 types of brain tumors. Our program must be robust under these uneven circumstances. Stratified 10 k-fold validation would be one way to address this.\n",
    "\n",
    "https://www.analyseup.com/python-machine-learning/stratified-kfold.html\n",
    "https://www.aans.org/en/Patients/Neurosurgical-Conditions-and-Treatments/Brain-Tumors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a202e22-7402-4b36-bfff-0d9ff1be7e56",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b76140d-5556-429a-84e7-2f7b507f4be0",
   "metadata": {},
   "source": [
    "[1.5 points]  Setup the training to use data expansion in Keras (also called data augmentation). Explain why the chosen data expansion techniques are appropriate for your dataset. You can use the keras ImageGenerator as a pre-processing step OR in the optimization loop. You can also use the Keras-cv augmenter (a separate package: https://keras.io/keras_cv/ Links to an external site.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8945720",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vb/cm8xdysn1pg36sgnx27zdnx40000gn/T/ipykernel_53107/3881119654.py:21: RuntimeWarning: invalid value encountered in true_divide\n",
      "  image /= (255)  #Normalize Values\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image  # Utilized Source [2]\n",
    "import matplotlib.pyplot as plt\n",
    "import struct\n",
    "\n",
    "\n",
    "# This method creates the data, whether training or testing, in the form we desire\n",
    "# Uses code from source [2] to create the training datasets\n",
    "def create_dataset(img_folder):\n",
    "    # Read through all files in \"./Training\"\n",
    "    img_data_array = []\n",
    "    class_name = []\n",
    "    \n",
    "    for dir1 in os.listdir(img_folder):\n",
    "        for file in os.listdir(os.path.join(img_folder, dir1)):\n",
    "            image_path = os.path.join(img_folder, dir1, file)\n",
    "            image = np.fromfile(image_path,dtype=np.float64)#.convert(\"L\").resize((512, 512))\n",
    "\n",
    "            image /= (255)  #Normalize Values\n",
    "            img_data_array.append(image)\n",
    "            class_name.append(dir1)\n",
    "    # return array with training data.\n",
    "    img_data_array = np.array(img_data_array, dtype=np.ndarray)\n",
    "    class_name = np.array(class_name, dtype=np.ndarray)\n",
    "    return img_data_array, class_name\n",
    "\n",
    "\n",
    "df_training, training_classes = create_dataset(\"./Training\")\n",
    "df_testing, testing_classes = create_dataset(\"./Testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318f3067-be7b-4579-bd46-ba8057ade761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63a6b24e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 22\u001b[0m\n\u001b[1;32m     16\u001b[0m mlp\u001b[38;5;241m.\u001b[39madd( Activation(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m) )\n\u001b[1;32m     18\u001b[0m mlp\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     19\u001b[0m               optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmsprop\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     20\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 22\u001b[0m df_training_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_training\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m mlp\u001b[38;5;241m.\u001b[39mfit(df_training,\n\u001b[1;32m     25\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m,\n\u001b[1;32m     26\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ML/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ML/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray)."
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "import tensorflow as tf\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "# make a 3 layer keras MLP\n",
    "mlp = Sequential()\n",
    "mlp.add( Flatten() ) # make images flat for the MLP input\n",
    "mlp.add( Dense(input_dim=1, units=30,\n",
    "               activation='relu') )\n",
    "mlp.add( Dense(units=15, activation='relu') )\n",
    "mlp.add( Dense(NUM_CLASSES) )\n",
    "mlp.add( Activation('softmax') )\n",
    "\n",
    "mlp.compile(loss='mean_squared_error',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['recall'])\n",
    "\n",
    "df_training_tensor = tf.convert_to_tensor(df_training) #Bruh this ain't working >:(\n",
    "\n",
    "mlp.fit(df_training,\n",
    "        batch_size=32, epochs=150,\n",
    "        shuffle=True, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bbbcd9b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 8, 8, 16)          80        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 4, 4, 16)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 4, 4, 16)          0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 1028      \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 4)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,108\n",
      "Trainable params: 1,108\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# make a CNN with conv layer and max pooling\n",
    "cnn = Sequential()\n",
    "cnn.add( Conv2D(filters=16, kernel_size= (2, 2), padding='same',\n",
    "                input_shape=(8,8,1),\n",
    "               ) )\n",
    "\n",
    "cnn.add( MaxPooling2D(pool_size=(2, 2)) )\n",
    "cnn.add( Activation('relu') )\n",
    "# add one layer on flattened output\n",
    "cnn.add( Flatten() )\n",
    "cnn.add( Dense(NUM_CLASSES) )\n",
    "cnn.add( Activation('softmax') )\n",
    "\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e4022f",
   "metadata": {},
   "source": [
    " Explain why the chosen data expansion techniques are appropriate for your dataset. :\n",
    " We used __ data expansion cause __"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af260c1",
   "metadata": {},
   "source": [
    "    Create a convolutional neural network to use on your data using Keras. Investigate at least two different convolutional network architectures (and investigate changing some parameters of each architecture such as the number of filters--at minimum have two variations of each network for a total of four models trained). Use the method of train/test splitting and evaluation metric that you argued for at the beginning of the lab. Visualize the performance of the training and validation sets per iteration (use the \"history\" parameter of Keras). Be sure that models converge.\n",
    "    [1.5 points] Visualize the final results of the CNNs and interpret/compare the performances. Use proper statistics as appropriate, especially for comparing models.\n",
    "    [1 points] Compare the performance of your convolutional network to a standard multi-layer perceptron (MLP) using the receiver operating characteristic and area under the curve. Use proper statistical comparison techniques.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b1f45d0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m         sns\u001b[38;5;241m.\u001b[39mheatmap(cm,annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;124m'\u001b[39m,xticklabels\u001b[38;5;241m=\u001b[39mlabels,yticklabels\u001b[38;5;241m=\u001b[39mlabels)\n\u001b[1;32m     24\u001b[0m         plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLP: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(acc_mlp))\n\u001b[0;32m---> 26\u001b[0m compare_mlp_cnn(cnn,mlp,\u001b[43mX_test\u001b[49m,y_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics as mt\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "def compare_mlp_cnn(cnn, mlp, X_test, y_test, labels='auto'):\n",
    "    plt.figure(figsize=(15,5))\n",
    "    if cnn is not None:\n",
    "        yhat_cnn = np.argmax(cnn.predict(X_test), axis=1)\n",
    "        acc_cnn = mt.accuracy_score(y_test,yhat_cnn)\n",
    "        plt.subplot(1,2,1)\n",
    "        cm = mt.confusion_matrix(y_test,yhat_cnn)\n",
    "        cm = cm/np.sum(cm,axis=1)[:,np.newaxis]\n",
    "        sns.heatmap(cm, annot=True, fmt='.2f',xticklabels=labels,yticklabels=labels)\n",
    "        plt.title('CNN: '+str(acc_cnn))\n",
    "\n",
    "    if mlp is not None:\n",
    "        yhat_mlp = np.argmax(mlp.predict(X_test), axis=1)\n",
    "        acc_mlp = mt.accuracy_score(y_test,yhat_mlp)\n",
    "        plt.subplot(1,2,2)\n",
    "        cm = mt.confusion_matrix(y_test,yhat_mlp)\n",
    "        cm = cm/np.sum(cm,axis=1)[:,np.newaxis]\n",
    "        sns.heatmap(cm,annot=True, fmt='.2f',xticklabels=labels,yticklabels=labels)\n",
    "        plt.title('MLP: '+str(acc_mlp))\n",
    "\n",
    "compare_mlp_cnn(cnn,mlp,X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81503535",
   "metadata": {},
   "source": [
    "Exceptional Work (1 points total)\n",
    "Use transfer learning to pre-train the weights of your initial layers of your CNN. Compare the performance when using transfer learning to training without transfer learning (i.e., compare to your best model from above) in terms of classification performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8086fcde",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "# manipulated from Keras Documentation\n",
    "#  https://keras.io/applications/\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "res_model = ResNet50(weights='imagenet')\n",
    "res_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523913a0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import itertools\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "if 'res_model' not in locals():\n",
    "    res_model = ResNet50(weights='imagenet')\n",
    "\n",
    "ESC_KEY = 27\n",
    "\n",
    "# setup some windows for viewing\n",
    "cv2.namedWindow(\"demowin1\")\n",
    "cv2.startWindowThread()\n",
    "\n",
    "# open the video card for capture\n",
    "vc = cv2.VideoCapture(0)\n",
    "\n",
    "if vc.isOpened():  # try to get the first frame\n",
    "    print (\"vc opened, getting first frame\")\n",
    "    rval, frame = vc.read()\n",
    "    # this will likely fail the first time\n",
    "    # the webcam often needs some time to open fully\n",
    "    key = 0\n",
    "else:\n",
    "    print (\"vc not open, exiting\")\n",
    "    key = ESC_KEY\n",
    "\n",
    "while key != ESC_KEY and vc.isOpened():  # the escape key and the capture device is open\n",
    "    rval, frame = vc.read()\n",
    "    key = cv2.waitKey(10)\n",
    "\n",
    "    if rval and frame is not None:\n",
    "\n",
    "        frame_to_show = cv2.pyrDown(frame)  # make smaller immediately\n",
    "        # grab the ROI in top left (will show later on)\n",
    "        frame_down = frame_to_show[0:224,0:224]\n",
    "\n",
    "        # increase contrast\n",
    "        img_yuv = cv2.cvtColor(frame_down, cv2.COLOR_BGR2YUV)\n",
    "        img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0])# equalize the histogram of the Y channel\n",
    "        frame_down = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)# convert the YUV image back to RGB format\n",
    "\n",
    "        # and then remove noise\n",
    "        frame_down = cv2.fastNlMeansDenoisingColored(frame_down,None,7,10,7,21)\n",
    "# h (Optional): filter strength (luminance). Larger h value removes noise but alsoÃŸ image details\n",
    "# hColor (Optional):  The same as h but for color components.\n",
    "#    For most images value equals 10 will be enough to remove noise and not distort colors\n",
    "# templateWindowSize (Optional): Size in pixels of the template patch that is used to compute weights. Should be odd.\n",
    "#    Recommended value 7 pixels\n",
    "# searchWindowSize (Optional): Size in pixels of the window that is used to compute weighted average for given pixel. Should be odd. Affect performance linearly: greater searchWindowsSize - greater denoising time.\n",
    "#    Recommended value 21 pixels\n",
    "\n",
    "        img = frame_down.copy() # make a copy for numpy\n",
    "\n",
    "        x = image.img_to_array(img[:,:,::-1]) # convert to numpy\n",
    "        x = np.expand_dims(x, axis=0) # add batch dimension\n",
    "        x = preprocess_input(x) # apply resnet presets\n",
    "\n",
    "        preds = res_model.predict(x) # get the predictions\n",
    "\n",
    "        # decode the results into a list of tuples (class, description, probability)\n",
    "        txt = str(decode_predictions(preds, top=3)[0])\n",
    "\n",
    "        cv2.putText(frame_to_show, txt, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, [255, 255, 255])\n",
    "        cv2.rectangle(frame_to_show, (0,0), (224,224), (255,255,255), 1)\n",
    "        cv2.imshow(\"demowin1\", frame_to_show)\n",
    "\n",
    "print('releasing...')\n",
    "cv2.waitKey(1)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07753f00-c07b-46b8-8464-03bc29a2cb5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
